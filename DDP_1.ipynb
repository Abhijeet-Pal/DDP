{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOeArXxMbfpH",
        "outputId": "826b1ab4-5cce-47e7-8985-a126cca0fd2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Folder: New_Dataset_080424\n",
            "Subfolders: ['Purple_Blotch_Annotated', 'Basal_Rot', 'Stemphylium_Blight']\n",
            "\n",
            "Folder: New_Dataset_261223\n",
            "Subfolders: ['Anthracnose', 'Healthy']\n",
            "\n",
            "Folder: New_Dataset-030923\n",
            "Subfolders: ['Healthy_Bulb', 'IYSV', 'Thrips Insect photo', 'Bulb Rot', 'Healthy_Seed', 'Thrips symtom']\n",
            "\n",
            "Folder: New_Dataset-220424\n",
            "Subfolders: ['Anthracnose', 'Healthy', 'Purple Blotch', 'Stemphylium', 'Twister']\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "root_path = '/content/drive/My Drive/Raw_Dataset'\n",
        "\n",
        "folders_dict = {}\n",
        "for folder_name in os.listdir(root_path):\n",
        "    folder_path = os.path.join(root_path, folder_name)\n",
        "    if os.path.isdir(folder_path):\n",
        "        folders_dict[folder_name] = []\n",
        "        if folder_name == 'New_Dataset_261223':\n",
        "          tfolder = os.listdir(folder_path)\n",
        "          folder_path = os.path.join(folder_path, tfolder[0])\n",
        "        for subfolder_name in os.listdir(folder_path):\n",
        "            subfolder_path = os.path.join(folder_path, subfolder_name)\n",
        "\n",
        "            if os.path.isdir(subfolder_path):\n",
        "                folders_dict[folder_name].append(subfolder_name)\n",
        "\n",
        "for folder, subfolders in folders_dict.items():\n",
        "    print(f\"Folder: {folder}\")\n",
        "    print(f\"Subfolders: {subfolders}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1TiXKvwcIm-",
        "outputId": "d3a2f95f-4afd-4e5e-a07f-8f81cabc1d39"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'New_Dataset_080424': ['Purple_Blotch_Annotated',\n",
              "  'Basal_Rot',\n",
              "  'Stemphylium_Blight'],\n",
              " 'New_Dataset_261223': ['Anthracnose', 'Healthy'],\n",
              " 'New_Dataset-030923': ['Healthy_Bulb',\n",
              "  'IYSV',\n",
              "  'Thrips Insect photo',\n",
              "  'Bulb Rot',\n",
              "  'Healthy_Seed',\n",
              "  'Thrips symtom'],\n",
              " 'New_Dataset-220424': ['Anthracnose',\n",
              "  'Healthy',\n",
              "  'Purple Blotch',\n",
              "  'Stemphylium',\n",
              "  'Twister']}"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "folders_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pP3L5sq4cYtI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "root_path = '/content/drive/My Drive/Raw_Dataset'\n",
        "jpg_files_dict = {}\n",
        "\n",
        "def collect_jpg_files(folder_path):\n",
        "    jpg_files = [f for f in os.listdir(folder_path) if f.lower().endswith('.jpg')]\n",
        "    jpg_files_paths = [os.path.join(folder_path, f) for f in jpg_files]\n",
        "    return jpg_files_paths\n",
        "\n",
        "for main_folder, subfolders in folders_dict.items():\n",
        "    main_folder_path = os.path.join(root_path, main_folder)\n",
        "    if main_folder == 'New_Dataset_261223':\n",
        "      tfolder = os.listdir(main_folder_path)\n",
        "      main_folder_path = os.path.join(folder_path, tfolder[0])\n",
        "    for subfolder in subfolders:\n",
        "        subfolder_path = os.path.join(main_folder_path, subfolder)\n",
        "\n",
        "        if os.path.isdir(subfolder_path):\n",
        "            jpg_files = collect_jpg_files(subfolder_path)\n",
        "            jpg_files_dict[subfolder] = jpg_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYp32TH8ho4l",
        "outputId": "a947fccf-11f3-42c4-d72a-7d947c22d03d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Subfolder: Purple_Blotch_Annotated\n",
            "Number of JPEG files: 197\n",
            "\n",
            "Subfolder: Basal_Rot\n",
            "Number of JPEG files: 140\n",
            "\n",
            "Subfolder: Stemphylium_Blight\n",
            "Number of JPEG files: 261\n",
            "\n",
            "Subfolder: Healthy_Bulb\n",
            "Number of JPEG files: 42\n",
            "\n",
            "Subfolder: IYSV\n",
            "Number of JPEG files: 754\n",
            "\n",
            "Subfolder: Thrips Insect photo\n",
            "Number of JPEG files: 240\n",
            "\n",
            "Subfolder: Bulb Rot\n",
            "Number of JPEG files: 669\n",
            "\n",
            "Subfolder: Healthy_Seed\n",
            "Number of JPEG files: 98\n",
            "\n",
            "Subfolder: Thrips symtom\n",
            "Number of JPEG files: 306\n",
            "\n",
            "Subfolder: Anthracnose\n",
            "Number of JPEG files: 204\n",
            "\n",
            "Subfolder: Healthy\n",
            "Number of JPEG files: 600\n",
            "\n",
            "Subfolder: Purple Blotch\n",
            "Number of JPEG files: 209\n",
            "\n",
            "Subfolder: Stemphylium\n",
            "Number of JPEG files: 400\n",
            "\n",
            "Subfolder: Twister\n",
            "Number of JPEG files: 317\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for subfolder, jpg_files in jpg_files_dict.items():\n",
        "    print(f\"Subfolder: {subfolder}\")\n",
        "    print(f\"Number of JPEG files: {len(jpg_files)}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zw08ThcApu8V"
      },
      "outputs": [],
      "source": [
        "healthy_files = jpg_files_dict.pop('Healthy')\n",
        "healthy_bulb_files = jpg_files_dict.pop('Healthy_Bulb')\n",
        "healthy_seed = jpg_files_dict.pop('Healthy_Seed')\n",
        "thrips_insect_photo = jpg_files_dict.pop('Thrips Insect photo')\n",
        "thrips_symptom = jpg_files_dict.pop('Thrips symtom')\n",
        "stemphylium_blight = jpg_files_dict.pop('Stemphylium_Blight')\n",
        "stemphylium = jpg_files_dict.pop('Stemphylium')\n",
        "merged_healthy_files = healthy_files + healthy_bulb_files + healthy_seed\n",
        "merged_thrips = thrips_insect_photo + thrips_symptom\n",
        "merged_stemphylium = stemphylium_blight + stemphylium\n",
        "purple_blotch_annotated = jpg_files_dict.pop('Purple_Blotch_Annotated')\n",
        "purple_blotch = jpg_files_dict.pop('Purple Blotch')\n",
        "merged_purple_blotch = purple_blotch_annotated + purple_blotch\n",
        "jpg_files_dict['Merged_Healthy'] = merged_healthy_files\n",
        "jpg_files_dict['merged_thrips'] = merged_thrips\n",
        "jpg_files_dict['merged_stemphylium'] = merged_stemphylium\n",
        "jpg_files_dict['merged_purple_blotch'] = merged_purple_blotch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJOVxJD3qJaL",
        "outputId": "f53c8cda-b129-4699-c40b-713ea6031b4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Subfolder: Basal_Rot\n",
            "Number of JPEG files: 140\n",
            "\n",
            "Subfolder: IYSV\n",
            "Number of JPEG files: 754\n",
            "\n",
            "Subfolder: Bulb Rot\n",
            "Number of JPEG files: 669\n",
            "\n",
            "Subfolder: Anthracnose\n",
            "Number of JPEG files: 204\n",
            "\n",
            "Subfolder: Twister\n",
            "Number of JPEG files: 317\n",
            "\n",
            "Subfolder: Merged_Healthy\n",
            "Number of JPEG files: 740\n",
            "\n",
            "Subfolder: merged_thrips\n",
            "Number of JPEG files: 546\n",
            "\n",
            "Subfolder: merged_stemphylium\n",
            "Number of JPEG files: 661\n",
            "\n",
            "Subfolder: merged_purple_blotch\n",
            "Number of JPEG files: 406\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for subfolder, jpg_files in jpg_files_dict.items():\n",
        "    print(f\"Subfolder: {subfolder}\")\n",
        "    print(f\"Number of JPEG files: {len(jpg_files)}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIQcuqSwuDjD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets, models\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLtuKJq-uGUS"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7RyYrSYuK5Y"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, jpg_files_dict, transform=None):\n",
        "        self.transform = transform\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "        self.label_map = {}\n",
        "        self._prepare_data(jpg_files_dict)\n",
        "\n",
        "    def _prepare_data(self, jpg_files_dict):\n",
        "        for label_idx, (subfolder, file_paths) in enumerate(jpg_files_dict.items()):\n",
        "            self.label_map[subfolder] = label_idx\n",
        "            for file_path in file_paths:\n",
        "                self.image_paths.append(file_path)\n",
        "                self.labels.append(label_idx)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        try:\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "        except (OSError, IOError) as e:\n",
        "            print(f'Error loading image {img_path}: {e}')\n",
        "            image = Image.new('RGB', (224, 224))\n",
        "            label = self.labels[idx]\n",
        "        else:\n",
        "            label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "dataset = CustomImageDataset(jpg_files_dict=jpg_files_dict, transform=transform)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9sLcTUsykGq"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "class_counts = []\n",
        "for subfolder, jpg_files in jpg_files_dict.items():\n",
        "    class_counts.append(len(jpg_files))\n",
        "def compute_class_weights(label_map, dataset):\n",
        "    class_weights = np.max(class_counts) / class_counts\n",
        "    class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "    return class_weights\n",
        "\n",
        "class_weights = compute_class_weights(dataset.label_map, dataset)\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RS4xw_wmuUTc"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89fswXBzuZYP",
        "outputId": "c3b74ae2-1a29-4edd-bca4-6a352d434e13"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Basal_Rot': 0,\n",
              " 'IYSV': 1,\n",
              " 'Bulb Rot': 2,\n",
              " 'Anthracnose': 3,\n",
              " 'Twister': 4,\n",
              " 'Merged_Healthy': 5,\n",
              " 'merged_thrips': 6,\n",
              " 'merged_stemphylium': 7,\n",
              " 'merged_purple_blotch': 8}"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.label_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkQFoNG_qbxO",
        "outputId": "1586179a-7831-49dd-b5d7-4de5c43cb0a8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "model = models.resnet50(pretrained=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAKdx9L-qekA",
        "outputId": "c5610c51-6a2a-4a58-9e0f-607997f30983"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Linear(in_features=2048, out_features=9, bias=True)\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "print(nn.Linear(2048, 9))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChPA5lvjuaWT",
        "outputId": "fc342396-e29d-4b38-f4d7-aa08b5c45de5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 129MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7578.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7116.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7631.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7118.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7113.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7698.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7557.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7182.JPG: broken data stream when reading image file\n",
            "Epoch 1/10 Loss: 1.2331 Accuracy: 0.6104\n",
            "Saved best model with accuracy: 0.6104\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7698.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7631.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7118.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7557.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7116.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7578.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7113.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7182.JPG: broken data stream when reading image file\n",
            "Epoch 2/10 Loss: 0.8087 Accuracy: 0.6453\n",
            "Saved best model with accuracy: 0.6453\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7631.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7118.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7698.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7578.JPG: broken data stream when reading image file\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "\n",
        "model = models.resnet50(pretrained=True)\n",
        "num_classes = len(jpg_files_dict)\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "criterion = criterion\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=5):\n",
        "    best_acc = 0.0\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "\n",
        "        model.eval()\n",
        "        corrects = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total += labels.size(0)\n",
        "                corrects += (predicted == labels).sum().item()\n",
        "\n",
        "        epoch_acc = corrects / total\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs} Loss: {epoch_loss:.4f} Accuracy: {epoch_acc:.4f}')\n",
        "\n",
        "        if epoch_acc > best_acc:\n",
        "            best_acc = epoch_acc\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "            print('Saved best model with accuracy: {:.4f}'.format(best_acc))\n",
        "\n",
        "    print('Training complete.')\n",
        "    print('Best Validation Accuracy: {:.4f}'.format(best_acc))\n",
        "\n",
        "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10)\n",
        "def evaluate_model(model, val_loader):\n",
        "    model.eval()\n",
        "    corrects = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            corrects += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = corrects / total\n",
        "    print(f'Validation Accuracy: {accuracy:.4f}')\n",
        "\n",
        "model.load_state_dict(torch.load('best_model.pth'))\n",
        "\n",
        "evaluate_model(model, val_loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_dtWPaSgigi",
        "outputId": "a271761a-2f54-496c-8200-e40bccf28057"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:01<00:00, 52.0MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7578.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7116.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7631.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7118.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7113.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7698.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7557.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7182.JPG: broken data stream when reading image file\n",
            "Epoch 1/20  Loss: 1.2331  Accuracy: 0.6000\n",
            "Saved best model with accuracy: 0.6000\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7578.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7116.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7631.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7118.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7113.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7698.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7557.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7182.JPG: broken data stream when reading image file\n",
            "Epoch 2/20  Loss: 1.1158  Accuracy: 0.6236\n",
            "Saved best model with accuracy: 0.6236\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7578.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7116.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7631.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7118.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7113.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7698.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7557.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7182.JPG: broken data stream when reading image file\n",
            "Epoch 3/20  Loss: 1.0096  Accuracy: 0.6429\n",
            "Saved best model with accuracy: 0.6429\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7578.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7116.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7631.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7118.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7113.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7698.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7557.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7182.JPG: broken data stream when reading image file\n",
            "Epoch 4/20  Loss: 0.9135  Accuracy: 0.6587\n",
            "Saved best model with accuracy: 0.6587\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7578.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7116.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7631.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7118.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7113.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7698.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7557.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7182.JPG: broken data stream when reading image file\n",
            "Epoch 5/20  Loss: 0.8266  Accuracy: 0.6716\n",
            "Saved best model with accuracy: 0.6716\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7578.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7116.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7631.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7118.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7113.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7698.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7557.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7182.JPG: broken data stream when reading image file\n",
            "Epoch 6/20  Loss: 0.7479  Accuracy: 0.6822\n",
            "Saved best model with accuracy: 0.6822\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7578.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7116.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7631.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7118.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7113.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7698.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7557.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7182.JPG: broken data stream when reading image file\n",
            "Epoch 7/20  Loss: 0.6767  Accuracy: 0.6908\n",
            "Saved best model with accuracy: 0.6908\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7578.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7116.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7631.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7118.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7113.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7698.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7557.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7182.JPG: broken data stream when reading image file\n",
            "Epoch 8/20  Loss: 0.6123  Accuracy: 0.6979\n",
            "Saved best model with accuracy: 0.6979\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7578.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7116.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7631.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7118.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7113.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7698.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7557.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7182.JPG: broken data stream when reading image file\n",
            "Epoch 9/20  Loss: 0.5541  Accuracy: 0.7038\n",
            "Saved best model with accuracy: 0.7038\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7578.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7116.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7631.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7118.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7113.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7698.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7557.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7182.JPG: broken data stream when reading image file\n",
            "Epoch 10/20  Loss: 0.5013  Accuracy: 0.7085\n",
            "Saved best model with accuracy: 0.7085\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7578.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7116.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7631.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7118.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7113.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7698.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7557.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7182.JPG: broken data stream when reading image file\n",
            "Epoch 11/20  Loss: 0.4536  Accuracy: 0.7124\n",
            "Saved best model with accuracy: 0.7124\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7578.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7116.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7631.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7118.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7113.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7698.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7557.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7182.JPG: broken data stream when reading image file\n",
            "Epoch 12/20  Loss: 0.4105  Accuracy: 0.7156\n",
            "Saved best model with accuracy: 0.7156\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7578.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7116.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7631.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7118.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7113.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7698.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7557.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7182.JPG: broken data stream when reading image file\n",
            "Epoch 13/20  Loss: 0.3714  Accuracy: 0.7182\n",
            "Saved best model with accuracy: 0.7182\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7578.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7116.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7631.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7118.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7113.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7698.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7557.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7182.JPG: broken data stream when reading image file\n",
            "Epoch 14/20  Loss: 0.3361  Accuracy: 0.7203\n",
            "Saved best model with accuracy: 0.7203\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7578.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7116.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7631.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7118.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7113.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7698.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7557.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7182.JPG: broken data stream when reading image file\n",
            "Epoch 15/20  Loss: 0.3041  Accuracy: 0.7221\n",
            "Saved best model with accuracy: 0.7221\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7578.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7116.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7631.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7118.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7113.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7698.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7557.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7182.JPG: broken data stream when reading image file\n",
            "Epoch 16/20  Loss: 0.2751  Accuracy: 0.7235\n",
            "Saved best model with accuracy: 0.7235\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7578.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7116.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7631.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7118.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7113.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7698.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7557.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7182.JPG: broken data stream when reading image file\n",
            "Epoch 17/20  Loss: 0.2490  Accuracy: 0.7247\n",
            "Saved best model with accuracy: 0.7247\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7578.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7116.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7631.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7118.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7113.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7698.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7557.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7182.JPG: broken data stream when reading image file\n",
            "Epoch 18/20  Loss: 0.2253  Accuracy: 0.7257\n",
            "Saved best model with accuracy: 0.7257\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7578.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7116.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7631.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7118.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7113.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7698.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7557.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7182.JPG: broken data stream when reading image file\n",
            "Epoch 19/20  Loss: 0.2038  Accuracy: 0.7264\n",
            "Saved best model with accuracy: 0.7264\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7578.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7116.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7631.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7118.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7113.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7698.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_21_11_2023_DSC_7557.JPG: broken data stream when reading image file\n",
            "Error loading image /content/drive/My Drive/Raw_Dataset/New_Dataset_080424/Purple_Blotch_Annotated/PB_D_E6_18_11_2023_DSC_7182.JPG: broken data stream when reading image file\n",
            "Epoch 20/20  Loss: 0.1844  Accuracy: 0.7271\n",
            "Saved best model with accuracy: 0.7271\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "losses = []\n",
        "validation_losses = []\n",
        "model = models.resnet50(pretrained=True)\n",
        "num_classes = len(jpg_files_dict)\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "criterion = criterion\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=5):\n",
        "    best_acc = 0.0\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "        losses.append(epoch_loss)\n",
        "        model.eval()\n",
        "        corrects = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total += labels.size(0)\n",
        "                corrects += (predicted == labels).sum().item()\n",
        "\n",
        "        epoch_acc = corrects / total\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs} Loss: {epoch_loss:.4f} Accuracy: {epoch_acc:.4f}')\n",
        "\n",
        "        if epoch_acc > best_acc:\n",
        "            best_acc = epoch_acc\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "            print('Saved best model with accuracy: {:.4f}'.format(best_acc))\n",
        "\n",
        "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=20)\n",
        "def evaluate_model(model, val_loader):\n",
        "    model.eval()\n",
        "    corrects = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            corrects += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = corrects / total\n",
        "    print(f'Validation Accuracy: {accuracy:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70QeM-gFhw8i",
        "outputId": "877d4f67-7693-48c0-b910-f7542222b646"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.6826\n"
          ]
        }
      ],
      "source": [
        "model.load_state_dict(torch.load('best_model.pth'))\n",
        "evaluate_model(model, val_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "pT3WME6Ellsc",
        "outputId": "c87faff3-7f00-4fa8-d327-2580e5c8cb51"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "epochs = 20\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(epochs), losses, color='blue', label='Training Loss')\n",
        "plt.title('Training  Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khaUppH-lmN-",
        "outputId": "6e78c300-7300-4aa2-b143-dde168223f6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Binary Crossentropy Loss: 2.3025851\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "binary_crossentropy = tf.keras.losses.BinaryCrossentropy()\n",
        "y_true = tf.constant([1.0])\n",
        "y_pred = tf.constant([0.1])\n",
        "loss = binary_crossentropy(y_true, y_pred)\n",
        "print(\"Binary Crossentropy Loss:\", loss.numpy())"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
